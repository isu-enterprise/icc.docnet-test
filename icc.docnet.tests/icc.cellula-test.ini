[local]
ROOT=/home/eugeneai/Development/codes/icc.docnet/tests/icc.docnet-test
DATA=${ROOT}/DATA

[app:main]
use = egg:isu.webapp

pyramid.reload_templates = true
pyramid.debug_authorization = false
pyramid.debug_notfound = false
pyramid.debug_routematch = false
pyramid.debug_templates = true
# pyramid.default_locale_name = en
pyramid.default_locale_name = ru

pyramid.includes = pyramid_debugtoolbar pyramid_chameleon pyramid_zcml icc.docnet.tests
debugtoolbar.hosts = 192.168.0.0/16 2001:470:dfda::/48 2001:470:72db::/48 2001:470:18fb::/48 127.0.0.0/8 ::1/128
content_storage=scanner

[mailer]
setup=gAAAAABYGxy538ZIP1UzS-EnMYizNY5uIZagfbCf2-oBPTVg_AjzynSVr5aUnjzV_7HZssy_Gq55SJE0cASrWfINpq6uYPDYx6bAXVRrFq23ABLl3yOkp0v-EIIlBAnaRgrEz5oW6FF_00YewcVrg-2Rz-ektJ1obz190LPcB83QtFIbyPD8e80=
default_sender = cellula-admin@irnok.net

[content_storage]
# Lookout! configurator sets 'file' as "<string>", i.e. with "'s!!!!
ROOT=${local:DATA}/index
TMP=${local:DATA}/tmp
file=content.kch
path=${ROOT}
# size limit in Mbytes
size=50

[locations_storage]
# Lookout! configurator sets 'file' as "<string>", i.e. with "'s!!!!
ROOT=${local:DATA}/index
TMP=${local:DATA}/tmp
file=locations.kch
path=${ROOT}
# size limit in Mbytes
size=50

[scanner_storage]
content_storage=content
locations_storage=locations
STORAGE=${local:DATA}/source
#dirs=${STORAGE}/ISDCT:${STORAGE}/_UNSORTED_
#dirs=${STORAGE}
dirs=${STORAGE}

[scanner]
bunch_size=2

[extractor]
#Do not use "'s here in string values, please!
tmp_path=${content_storage:TMP}

[tracker]
tmp_path=${content_storage:TMP}
exec_path=/usr/lib/tracker

[recoll]
tmp_path=${content_storage:TMP}
mimeconf=/usr/share/recoll/examples/mimeconf
filter_dir=/usr/share/recoll/filters

[indexer]
data_dir=${content_storage:ROOT}/indexes
pid_file=index.pid
conf_file=index.conf
batch_amount=200

[rdf_storages]
all=persistent, temporal

[rdf_storage_persistent]
# It seems not used already
data_dir=${content_storage:ROOT}/rdf
data_file=world.kch
driver=KyotoCabinet

[rdf_storage_temporal]
driver=default

[graphs]
#Graphs are created and registered as utilities
#in the folloving very order
#all=ns, meta, org, document, tmp, fiber, persistent, temporal, world
all=document

[graph_ns]
#special graph, storing namespaces.
storage=temporal
load_from=icc.cellula:data/ontologies/namespaces.n3

[graph_meta]
# Contains all mata definitions in RDFS
storage=temporal

[graph_world]
contains=persistent, temporal
storage=temporal

[graph_org]
storage=persistent

[graph_document]
storage=persistent

[graph_tmp]
storage=temporal

[graph_fiber]
storage=persistent

[graph_persistent]
contains=org, document, fiber
storage=persistent

[graph_temporal]
contains=meta, tmp
storage=temporal

[sphinx]
mode=rt

[indexfeeder]
port=8082
host=[::1]
api=/api-fields

[workers]
#threads=4
threads=1
processes=0
ROOT=${HOME}/tmp/cellula-data
TMP=${ROOT}/tmp

[pengines]
host=irnok.net
port=3030

[sparql]
host=127.0.0.1
port=3030

[server:main]
use = egg:waitress#main
host = *
port=8082

# Begin logging configuration

[loggers]
#keys = root, icc, icc.cellula, waitress, sphinxapi
keys = root, icc.cellula, waitress
#, icc.cellula, waitress, sphinxapi

[handlers]
keys = console, filelog

[formatters]
keys = generic

[logger_root]
level = DEBUG
#level = CRITICAL
handlers = console, filelog

[logger_icc.cellula]
level = DEBUG
#level = INFO
handlers = console, filelog
qualname = icc.cellula
propagate=0

[logger_sphinxapi]
#level = DEBUG
handlers = console, filelog
qualname = sphinxapi
propagate=0

[handler_console]
class = StreamHandler
#args = (sys.stderr,)
args = (sys.stdout,)
#level = NOTSET
level = DEBUG
formatter = generic

[handler_filelog]
class = FileHandler
args = ("run.log", "w")
level = DEBUG
formatter = generic

[logger_waitress]
level = INFO
handlers = console, filelog
qualname = waitress
propagate=0

[formatter_generic]
#format = %(asctime)s[%(levelname)-5.5s] %(name)s:%(threadName)s: %(message)s
## format = %(asctime)s_%(levelname)s_%(name)s:%(threadName)s: %(message)s
#format = %(threadName)s
#       %(message)s
format = %(message)s

# End logging configuration

[maintainance]
# Maintain consistency of databases
keys=metadata

[maintainance_metadata]
#How many documents to process at a time
bunch=1

[elastic]
URL=http://localhost:9200/
index=metadata-test
# Timouts in seconds
timeout.ui=60
timeout.service=60

[marc]
# Number of records to import in one task
bunch_size = 100
URL=${elastic:URL}
index=marc-test
timeout.ui=${elastic:timeout.ui}
timeout.service=${elastic:timeout.service}
